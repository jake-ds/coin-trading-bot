# Ralph Progress Log
Started: 2026년 2월 23일 월요일 17시 18분 03초 KST
---

## Codebase Patterns

### Circular Import: research ↔ engines
- `bot.research.base` → `bot.engines.tuner` (ParamChange) → `bot.engines.__init__` → `bot.engines.manager` → `bot.research.base` (circular!)
- Fix: `bot.research/__init__.py` uses lazy `__getattr__` imports instead of module-level imports
- Existing tests work only because they import engines before research (by coincidence)
- Any new module in research/ can be imported directly (`from bot.research.data_provider import X`) without triggering the circular chain

### DataStore Patterns
- `get_candles()` returns `list[OHLCV]` (Pydantic models), sorted oldest→newest
- `get_funding_rates()` returns `list[dict]` with keys: symbol, timestamp, funding_rate, funding_timestamp, mark_price, spot_price, spread_pct
- New query methods: just add async methods using `self._session_factory()` context manager
- `func.count()` from sqlalchemy for aggregate queries

### Testing Patterns
- Use `MagicMock()` for DataStore, set async methods via `AsyncMock(return_value=...)`
- Existing 3 pre-existing test failures (not our fault): test_defaults, test_main_without_validate_runs_trading_loop, test_main_without_args_runs_trading_loop
- Baseline: 2274 passed + 3 pre-existing failures

---

## 2026-02-23 - V6-001
- **Implemented**: HistoricalDataProvider — thin wrapper over DataStore for research experiments
- **Files created**:
  - `src/bot/research/data_provider.py` — HistoricalDataProvider class with get_prices, get_ohlcv, get_returns, get_funding_rates, get_multi_prices, get_available_symbols
  - `tests/research/test_data_provider.py` — 20 tests covering all methods, empty data, lookback filtering
- **Files modified**:
  - `src/bot/data/store.py` — Added `get_available_symbols(timeframe, min_count)` async method (DISTINCT symbol with GROUP BY HAVING)
  - `src/bot/research/__init__.py` — Converted to lazy `__getattr__` imports to fix circular dependency; exports HistoricalDataProvider
- **Tests**: 20 new, 2219 total passing (+ 3 pre-existing failures)
- **Learnings for future iterations:**
  - research/__init__.py MUST use lazy imports — never add eager imports there
  - _CANDLES_PER_DAY mapping handles timeframe→limit conversion (1h=24, 4h=6, 1d=1, etc.)
  - get_multi_prices uses asyncio.gather for parallel fetching
  - Funding rates come 3/day (8h interval), so limit = days × 3

### DataCollector Patterns
- `_dynamic_symbols: set[str]` holds scanner-discovered symbols
- `collect_once()` iterates over `dict.fromkeys(self._symbols + sorted(self._dynamic_symbols))` for dedup
- `bulk_backfill()` uses existing `backfill()` per symbol with 0.5s rate limit between calls
- `TIMEFRAME_SECONDS` dict maps timeframe→seconds; use `86400 // tf_seconds` for candles/day
- `auto_discover_symbols()` takes an OpportunityRegistry and iterates all OpportunityType enum values
- `_backfill_loop()` takes registry + settings as args (not stored), runs every `data_backfill_interval_hours`

### EngineManager Wiring
- `set_collector(collector)` stores DataCollector reference for backfill loop
- `start_background_loops()` starts backfill task if `data_backfill_enabled` and collector is set
- `opportunity_registry` property fetches registry from token_scanner engine
- `start_background_loops()` was NOT called in main.py `_run_engine_mode()` — added it after `start_all()`

---

## 2026-02-23 - V6-002
- **Implemented**: DataCollector batch backfill + scanner auto-discovery
- **Files created**:
  - `tests/data/test_backfill.py` — 22 tests: bulk_backfill, auto_discover, dynamic_symbols merge, backfill_loop, config, EngineManager wiring
- **Files modified**:
  - `src/bot/data/collector.py` — Added `_dynamic_symbols`, `bulk_backfill()`, `auto_discover_symbols()`, `_backfill_loop()`. Modified `collect_once()` to include dynamic symbols
  - `src/bot/config.py` — Added `data_backfill_enabled`, `data_backfill_interval_hours`, `data_backfill_days` settings + SETTINGS_METADATA
  - `src/bot/engines/manager.py` — Added `_collector`, `_backfill_task`, `set_collector()`. Updated `start_background_loops()` to start backfill loop
  - `src/bot/main.py` — Added `set_collector()` call in `_init_engine_mode()`, added `start_background_loops()` call in `_run_engine_mode()`
- **Tests**: 22 new, 2241 total passing (+ 3 pre-existing failures)
- **Learnings for future iterations:**
  - `start_background_loops()` was defined but never called — fixed
  - Rate limit delay between symbols is 0.5s (using `asyncio.sleep`)
  - `dict.fromkeys()` preserves order while deduplicating
  - Backfill loop uses registry from `opportunity_registry` property (finds scanner engine)

### Research Experiment Data Flow
- `ResearchTask` base class stores `data_provider: HistoricalDataProvider | None` (default None for backward compat)
- `_run_async(coro)` helper in ResearchTask: runs async code from sync `run_experiment()` — uses ThreadPoolExecutor when inside running event loop, `asyncio.run()` otherwise
- Data priority in experiments: `kwargs` > `data_provider` > synthetic fallback
- Each experiment adds `data_source: 'real' | 'synthetic' | 'kwargs'` to results dict
- CointegrationExperiment accepts `stat_arb_pairs` list, OptimalGridExperiment accepts `grid_symbols` list
- FundingPrediction: `_real_funding_data` stores raw records for time pattern analysis (hourly/daily)
- Experiments registered in `main.py._register_research_experiments()` with data_provider from DataStore

---

## 2026-02-23 - V6-003
- **Implemented**: Research experiments real data upgrade — all 4 experiments use HistoricalDataProvider
- **Files created**:
  - `tests/research/test_experiments_real_data.py` — 33 tests: real data mode, fallback to synthetic, data_source field, time pattern analysis, backward compatibility
- **Files modified**:
  - `src/bot/research/base.py` — Added `__init__(data_provider=None)` to ResearchTask ABC, `_run_async()` helper for sync→async bridging
  - `src/bot/research/experiments/volatility_regime.py` — Added `data_provider` param, `_fetch_real_prices()`, `data_source` in results
  - `src/bot/research/experiments/cointegration.py` — Added `data_provider` + `stat_arb_pairs` params, `_fetch_real_pairs()`, `data_source` in results
  - `src/bot/research/experiments/optimal_grid.py` — Added `data_provider` + `grid_symbols` params, `_fetch_real_prices()`, `data_source` in results
  - `src/bot/research/experiments/funding_prediction.py` — Added `data_provider` param, `_fetch_real_funding_rates()`, time pattern analysis (`_analyze_time_patterns()`), `data_source`/`best_entry_hour`/`avg_positive_rate`/`hourly_pattern`/`daily_pattern` in results
  - `src/bot/main.py` — Added `_register_research_experiments()` method that creates all 4 experiments with HistoricalDataProvider and registers them on EngineManager
  - `scripts/ralph/prd.json` — Marked V6-003 passes: true
- **Tests**: 33 new, 2274 total passing (+ 3 pre-existing failures)
- **Learnings for future iterations:**
  - `_run_async()` pattern: `ThreadPoolExecutor` + `asyncio.run` for running async from sync inside event loop
  - Each experiment's `__init__` must call `super().__init__(data_provider=data_provider)` to store on base
  - Funding rate timestamps can be `datetime` objects or epoch milliseconds (int) — handle both
  - experiments/__init__.py uses eager imports (not lazy) — safe since it doesn't import from engines
  - `data_source` field is always present in results for V6-003+, enabling downstream analysis of data quality
---
